{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "A2M_Metabolic_Features_Filtering_v1.3.rp.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNL0Fu+4Gb6bFVjZh7rpYRg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/2AMissinou/Metabolomics-Filtering/blob/main/A2M_Metabolic_Features_Filtering_v1_3_rp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **<font color='\tdodgerblue'> Metabolic features Clean up and Multivariate analysis **<font>\n",
        "\n",
        "---\n",
        "\n",
        "Authors: Anani Amegan Missinou (anani.a.missinou@gmail.com) <br>\n",
        "Input file format: .csv files or .txt files <br>\n",
        "Outputs: .csv files  <br>\n",
        "Dependencies: ggplot2, dplyr, ecodist, vegan, svglite\\"
      ],
      "metadata": {
        "id": "jru5YQzJtvgI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run rmagic by executing this command %load_ext rpy2. ipython .\n",
        "After that, every time you want to use R, add %%R in the beginning of each cell. Start rmagic by executing this in a cell: %load_ext rpy2. ipython. Use %%R to execute cell magic\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Zpmp9RTTeu7W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext rpy2.ipython"
      ],
      "metadata": {
        "id": "_S0juWqcunoG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "#installing and calling the necessary packages:\n",
        "install.packages(\"ggplot2\")\n",
        "install.packages(\"dplyr\")\n",
        "install.packages(\"ecodist\") #for PCoA using Bray Curtis distance\n",
        "install.packages(\"vegan\") #for PermANOVA\n",
        "install.packages(\"svglite\") # for saving ggplots as svg files\n",
        "install.packages(\"tidyverse\")"
      ],
      "metadata": {
        "id": "-0XpPEoWuk0F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Rym0mXNMZ7B"
      },
      "outputs": [],
      "source": [
        "%%R\n",
        "require(\"ggplot2\")\n",
        "require(\"dplyr\")\n",
        "require(\"ecodist\")\n",
        "require(\"vegan\")\n",
        "require(\"svglite\")\n",
        "require(\"tidyverse\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Recipes for loading and saving data from external sources\n",
        "\n",
        "Alternatively, we can updoad/import from your local file systemor  mount and read data  directly pull the data files from Github page:\n",
        "\n"
      ],
      "metadata": {
        "id": "XdeaBujhw2pq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Upload/Import files from your local file system"
      ],
      "metadata": {
        "id": "U3lNH2vff8Bx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))"
      ],
      "metadata": {
        "id": "LMQ36zR6yRwH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Write and downlad file to your local file system"
      ],
      "metadata": {
        "id": "x0CCow-ofMyH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p2E4EKhCWEC5"
      },
      "outputs": [],
      "source": [
        "\n",
        "from google.colab import files\n",
        "\n",
        "with open('example.txt', 'w') as f:\n",
        "  f.write('some content')\n",
        "\n",
        "files.download('example.txt')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Mount and Read the input data using URL (from Github):\n"
      ],
      "metadata": {
        "id": "0rAnOP_CYvLU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google drive directory \n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "id": "Zc0fQZwUE7c5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setting a local working directory and creating an automatic result directory:\n",
        "Works well with Jupyter Notebook. If you are working with Jupyter Notebook, you can simply copy the folder path from your local computer to the next cell output line. It will be set as your working directory <br> \n",
        "For ex: D:\\User\\Project\\Test_Data <br>\n",
        "<br>\n",
        "For Google Collab, we can upload the necessary files into a new folder using the 'Files' icon on the left and set the folder as working directory. And all the ouput files will be saved here as well and you need to download them finally into your local computer"
      ],
      "metadata": {
        "id": "MKFubSt_YhCr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "# setting the current directory as the working directory\n",
        "#Directory <- normalizePath(readline(\"Enter the path of the folder with input files: \"),\"/\",mustWork=FALSE)\n",
        "#setwd(Directory)\n",
        "setwd(\"/content/drive/MyDrive/Data Science Training/CMFI_Seminar_Multivariate_Statistics\")\n"
      ],
      "metadata": {
        "id": "_DdM19cgY9Jc"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "getwd()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8lXzvXdDac8H",
        "outputId": "3ac8a266-7be4-4f41-c99d-e7f25bf60bdc"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1] \"/content/drive/MyDrive/Data Science Training/CMFI_Seminar_Multivariate_Statistics\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "# Getting all the files in the folder\n",
        "dirs <- dir(path=paste(getwd(), sep=\"\"), full.names=TRUE, recursive=TRUE)\n",
        "folders <- unique(dirname(dirs))\n",
        "files <- list.files(folders, full.names=TRUE)\n",
        "files_1 <- basename((files))\n",
        "files_2 <- dirname((files))\n",
        "# Creating a Result folder\n",
        "dir.create(path=paste(files_2[[1]], \"_Results\", sep=\"\"), showWarnings = TRUE)\n",
        "fName <-paste(files_2[[1]], \"_Results\", sep=\"\")\n",
        "\n",
        "print(files_1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dx1uAIeyZBO0",
        "outputId": "42f18a9a-7ee0-4507-a920-ef711c7a5a2c"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1] \"Normalised_Quant_table.csv\"                                       \n",
            "[2] \"Quant_Table_filled_with_MinValue_3766.csv\"                        \n",
            "[3] \"20220716_Xenobiotic_metabolism_gapfilled_quant_Bsub.csv\"          \n",
            "[4] \"20220716_Xenobiotic_metabolism_gapfilled_quant_Bsub.mgf\"          \n",
            "[5] \"20220716_Xenobiotic_Metabolism_metadata_Bsub.txt\"                 \n",
            "[6] \"20220716_Xenobiotic_metabolism_non_gapfilled_quant_Bsub_quant.csv\"\n",
            "[7] \"20220716_Xenobiotic_metabolism_non_gapfilled_quant_Bsub.mgf\"      \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**<font color='orange'> In the following line, enter the required file ID numbers separated by commas. For example as: 1,2,3 </font>**"
      ],
      "metadata": {
        "id": "f6gtPA8AbJ1s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "input <- as.double(unlist(strsplit(readline(\"Specify the file index of gapfilled & non-gapfilled feature-file, metadata:\"), split=\",\")))\n",
        "\n",
        "#Gets the extension of each file. Ex:csv\n",
        "pattern <- c()\n",
        "for (i in files_1){\n",
        "  sep_file <- substr(i, nchar(i)-2,nchar(i))\n",
        "  pattern <- rbind(pattern,sep_file)\n",
        "}\n",
        "#pattern\n",
        "\n",
        "ft <- read.csv(files_1[input[1]],sep = ifelse(pattern[input[1]]!=\"csv\",\"\\t\",\",\"), header=TRUE,check.names = FALSE) # By applying 'row.names = 1', the 1st column 'ID' becomes the row names\n",
        "nft<- read.csv(files_1[input[2]],sep=ifelse(pattern[input[2]]!=\"csv\",\"\\t\",\",\"), header = TRUE,check.names = FALSE)\n",
        "md <-read.csv(files_1[input[3]], sep = ifelse(pattern[input[3]]!=\"csv\",\"\\t\",\",\"), header=TRUE,check.names = FALSE)"
      ],
      "metadata": {
        "id": "vhPc56MAbgNl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "nft <- read.csv(nft_url, header = T, check.names = F)\n",
        "ft <- read.csv(ft_url, header = T, check.names = F)\n",
        "md <- read.csv(md_url, header = T, check.names = F, sep = '\\t')"
      ],
      "metadata": {
        "id": "rP9xMdh0b-fu"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check if the data has been read correclty!!"
      ],
      "metadata": {
        "id": "oqMViRQ-dhN-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "head(nft)\n",
        "dim(nft)"
      ],
      "metadata": {
        "id": "DUKAB_90_58y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%R \n",
        "head(ft)\n",
        "dim(ft)"
      ],
      "metadata": {
        "id": "eKFl4KVyQ0tw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "head(md)\n",
        "dim(md)"
      ],
      "metadata": {
        "id": "-7AYcCnsABut"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Trying to bring the feature table and metadata in the correct format such as the rownames of metadata and column names of feature table are the same. They both are the file names and they need to be same as from now on, we will call the columns in our feature table based on our metadata information. Thus, using the metadata, the user can filter their data easily. You can also directly deal with your feature table without metadata by getting your hands dirty with some coding!! But having a metadata improves the user-experience greatly."
      ],
      "metadata": {
        "id": "MDUhvPzlAc1T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Reading the input data using URL (from Github):\n",
        "# Alternatively, we can also directly pull the data files from our Functional Metabolomics Github page:\n",
        "\n",
        "%%R\n",
        "## Non-gap filled\n",
        "nft_url <- 'https://github.com/2AMissinou/Metabolomics-Filtering/tree/main/CMFI_Seminar_Multivariate_Statistics-main/Test_Data/20220716_Xenobiotic_metabolism_non_gapfilled_quant_Bsub_quant.csv'\n",
        "## Gap filled\n",
        "ft_url <- 'https://github.com/2AMissinou/Metabolomics-Filtering/tree/main/CMFI_Seminar_Multivariate_Statistics-main/Test_Data/20220716_Xenobiotic_metabolism_gapfilled_quant_Bsub.csv'\n",
        "md_url <- 'https://github.com/2AMissinou/Metabolomics-Filtering/tree/main/CMFI_Seminar_Multivariate_Statistics-main/Test_Data/20220716_Xenobiotic_Metabolism_metadata_Bsub.txt'"
      ],
      "metadata": {
        "id": "cPTOllNS8-jf"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "#Removing Peak area extensions\n",
        "colnames(ft) <- gsub(' Peak area','',colnames(ft))\n",
        "colnames(nft) <- gsub(' Peak area','',colnames(nft))\n",
        "md$filename<- gsub(' Peak area','',md$filename)\n",
        "\n",
        "#Removing if any NA columns present in the md file\n",
        "ft <- ft[,colSums(is.na(ft))<nrow(ft)]\n",
        "nft <- nft[,colSums(is.na(nft))<nrow(nft)]\n",
        "md <- md[,colSums(is.na(md))<nrow(md)]\n",
        "\n",
        "#Changing the row names of the files\n",
        "rownames(md) <- md$filename\n",
        "md <- md[,-1]\n",
        "rownames(ft) <- paste(ft$'row ID',round(ft$'row m/z',digits = 3),round(ft$'row retention time',digits = 3), sep = '_')\n",
        "rownames(nft) <- paste(nft$'row ID',round(nft$'row m/z',digits = 3),round(nft$'row retention time',digits = 3), sep = '_')\n",
        "\n",
        "#Picking only the files with column names containing 'mzML'\n",
        "ft <- ft[,grep('mzML',colnames(ft))]\n",
        "nft <- nft[,grep('mzML',colnames(nft))]\n",
        "\n",
        "# Converting replicate attributes into factors (categorical data)\n",
        "md$ATTRIBUTE_replicates <- as.factor(md$ATTRIBUTE_replicates)"
      ],
      "metadata": {
        "id": "uhsqFX5FEGR5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "# setting the current directory as the working directory\n",
        "Directory <- normalizePath(readline(\"Enter the path of the folder with input files: \"),\"/\",mustWork=FALSE)\n",
        "setwd(Directory)\n",
        "\n",
        "## recommanded format : 'D:/Parts/DATA/Metabolomics/Metabolomics_tools/CMFI Mass Spec Seminar Series/#14 - Feature-Table Data Clean-Up and Multivariate Analysis'"
      ],
      "metadata": {
        "id": "xSP2RW9nKbEn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}